{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b607bfb4-872e-4e69-8be2-cbc7a6c686e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# These are the default AWS configurations for the Analysis Sandbox.\n",
    "# that are set in the environmnet variables.\n",
    "aws_default_config = {\n",
    "    # \"AWS_NO_SIGN_REQUEST\": \"YES\",\n",
    "    \"AWS_SECRET_ACCESS_KEY\": \"fake\",\n",
    "    \"AWS_ACCESS_KEY_ID\": \"fake\",\n",
    "}\n",
    "\n",
    "# To access public bucket, need to remove the AWS credentials in\n",
    "# the environment variables or the following error will occur.\n",
    "# PermissionError: The AWS Access Key Id you provided does not exist in our records.\n",
    "\n",
    "for key in aws_default_config.keys():\n",
    "    if key in os.environ:\n",
    "        del os.environ[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c399025b-61f8-40bf-9c0f-5619e8a8b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "from importlib import import_module\n",
    "\n",
    "import click\n",
    "import fsspec\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "from deafrica_waterbodies.attributes import (\n",
    "    add_area_and_perimeter_attributes,\n",
    "    add_timeseries_attribute,\n",
    "    assign_unique_ids,\n",
    ")\n",
    "from deafrica_waterbodies.cli.logs import logging_setup\n",
    "from deafrica_waterbodies.filters import filter_by_area\n",
    "from deafrica_waterbodies.io import (\n",
    "    check_dir_exists,\n",
    "    check_file_exists,\n",
    "    check_if_s3_uri,\n",
    "    find_parquet_files,\n",
    "    write_waterbodies_to_file,\n",
    ")\n",
    "from deafrica_waterbodies.make_polygons import (\n",
    "    merge_polygons_at_tile_boundaries,\n",
    "    process_raster_polygons,\n",
    "    set_wetness_thresholds,\n",
    ")\n",
    "from deafrica_waterbodies.plugins.utils import run_plugin, validate_plugin\n",
    "from deafrica_waterbodies.tiling import get_wofs_ls_summary_alltime_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c92d45c-5adc-4fc9-8c40-b216f3a005a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=1\n",
    "aoi_vector_file=None\n",
    "tile_size_factor=4\n",
    "num_workers=8\n",
    "detection_threshold=0.1\n",
    "extent_threshold=0.05\n",
    "min_valid_observations=60\n",
    "raster_processing_plugin_name=\"ocean_filtering_using_hydrosheds\"\n",
    "output_directory = \"s3://deafrica-waterbodies-dev/waterbodies/v0.0.2/historical_extent/\"\n",
    "overwrite=\"True\"\n",
    "min_polygon_size=4500\n",
    "max_polygon_size=math.inf\n",
    "timeseries_directory = \"s3://deafrica-waterbodies-dev/waterbodies/v0.0.2/surface_area_change/\"\n",
    "file_name_prefix=\"waterbodies\"\n",
    "land_sea_mask_fp=\"/g/data/deafrica-waterbodies/masks/af_msk_3s.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7132d9d-f150-48d5-90f7-b83ada1758c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger.\n",
    "logging_setup(verbose=verbose)\n",
    "_log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "184184d8-1921-4f70-b9d6-3c7795a5e78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to use when loading datasets.\n",
    "dask_chunks = {\"x\": 3200, \"y\": 3200, \"time\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcdac149-a47d-47d2-a306-7b8a1815f949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support pathlib Paths.\n",
    "if aoi_vector_file is not None:\n",
    "    aoi_vector_file = str(aoi_vector_file)\n",
    "\n",
    "output_directory = str(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42cc868e-9542-48a3-947a-0938ec225fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the filesystem to use.\n",
    "if check_if_s3_uri(output_directory):\n",
    "    fs = fsspec.filesystem(\"s3\")\n",
    "else:\n",
    "    fs = fsspec.filesystem(\"file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67e4e31c-4871-418c-96d6-081152a73ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-17 07:41:18,344] {credentials.py:611} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "# Directory to write generated waterbody polygons to.\n",
    "polygons_from_thresholds_dir = os.path.join(output_directory, \"polygons_from_thresholds\")\n",
    "\n",
    "# Check if the directory exists. If it does not, create it.\n",
    "if not check_dir_exists(polygons_from_thresholds_dir):\n",
    "    fs.mkdirs(polygons_from_thresholds_dir, exist_ok=True)\n",
    "    _log.info(f\"Created directory {polygons_from_thresholds_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75aa5e30-f4a3-4e88-8e55-4fcab4de580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the area of interest as a GeoDataFrame.\n",
    "if aoi_vector_file is not None:\n",
    "    try:\n",
    "        aoi_gdf = gpd.read_file(aoi_vector_file)\n",
    "    except Exception as error:\n",
    "        _log.exception(f\"Could not read the file {aoi_vector_file}\")\n",
    "        raise error\n",
    "else:\n",
    "    aoi_gdf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7569db1-2ad2-40dc-8b58-97c2fdc0c574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-17 07:41:18,606] {tiling.py:113} INFO - New tile size is (384000.0, 384000.0).\n",
      "[2023-11-17 07:41:20,674] {tiling.py:132} INFO - Number of wofs_ls_summary_alltime tiles: 329\n"
     ]
    }
   ],
   "source": [
    "# Get the tiles fo the wofs_ls_summary_alltime product.\n",
    "tiles, grid_workflow = get_wofs_ls_summary_alltime_tiles(\n",
    "    aoi_gdf=aoi_gdf, tile_size_factor=tile_size_factor, num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a97737d0-e14d-456a-9167-3960106552d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-17 07:41:20,680] {make_polygons.py:69} INFO - We will be running a hybrid wetness threshold.\n",
      "        You have set 0.1 as the location threshold, which will define the location of the water body polygons.\n",
      "        You have set 0.05 as the extent threshold, which will define the extent/shape of the water body polygons.\n"
     ]
    }
   ],
   "source": [
    "# Set the wetness thresholds.\n",
    "min_wet_thresholds = set_wetness_thresholds(\n",
    "    detection_threshold=detection_threshold, extent_threshold=extent_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c06fc4c1-8ad0-46db-b5e8-45bf695ad7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-17 07:41:20,708] {136687532.py:7} INFO - Using plugin /home/jovyan/dev/deafrica-waterbodies/deafrica_waterbodies/plugins/ocean_filtering_using_hydrosheds.py\n"
     ]
    }
   ],
   "source": [
    "# Set filters to apply during raster processing.\n",
    "if raster_processing_plugin_name is not None:\n",
    "    # Read the plugin as a Python module.\n",
    "    module = import_module(f\"deafrica_waterbodies.plugins.{raster_processing_plugin_name}\")\n",
    "    plugin_file = module.__file__\n",
    "    plugin = run_plugin(plugin_file)\n",
    "    _log.info(f\"Using plugin {plugin_file}\")\n",
    "    validate_plugin(plugin)\n",
    "else:\n",
    "    plugin = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3954c2-b769-4a8c-ac55-b3f1c9242ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-17 07:41:20,715] {1473515291.py:18} INFO - Generating water body polygons for tile (42, 24).\n"
     ]
    }
   ],
   "source": [
    "# Generate the first set of polygons for each of the tiles.\n",
    "for tile in tiles.items():\n",
    "    tile_id = tile[0]\n",
    "    raster_polygons_fp = os.path.join(\n",
    "        polygons_from_thresholds_dir, f\"{tile_id[0]}_{tile_id[1]}_raster_polygons.parquet\"\n",
    "    )\n",
    "\n",
    "    if not overwrite:\n",
    "        _log.info(f\"Checking existence of {raster_polygons_fp}\")\n",
    "        exists = check_file_exists(raster_polygons_fp)\n",
    "        if exists:\n",
    "            _log.info(\n",
    "                f\"{raster_polygons_fp} exists! \\n Skipping generating water body polygons for {tile_id}.\"\n",
    "            )\n",
    "\n",
    "    if overwrite or not exists:\n",
    "        try:\n",
    "            _log.info(f\"Generating water body polygons for tile {tile_id}.\")\n",
    "            raster_polygons = process_raster_polygons(\n",
    "                tile=tile,\n",
    "                grid_workflow=grid_workflow,\n",
    "                plugin=plugin,\n",
    "                dask_chunks=dask_chunks,\n",
    "                min_valid_observations=min_valid_observations,\n",
    "                min_wet_thresholds=min_wet_thresholds,\n",
    "                land_sea_mask_fp=land_sea_mask_fp,\n",
    "            )\n",
    "            if raster_polygons.empty:\n",
    "                _log.info(f\"Tile {str(tile_id)} contains no water body polygons.\")\n",
    "            else:\n",
    "                # Drop the attributes column if it exists.\n",
    "                raster_polygons.drop(columns=[\"attribute\"], errors=\"ignore\", inplace=True)\n",
    "                # Write the polygons to parquet files.\n",
    "                raster_polygons.to_parquet(raster_polygons_fp)\n",
    "                _log.info(\n",
    "                    f\"Tile {str(tile_id)} water body polygons written to {raster_polygons_fp}\"\n",
    "                )\n",
    "        except Exception as error:\n",
    "            _log.exception(f\"\\nTile {str(tile_id)} did not run. \\n\")\n",
    "            _log.exception(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0768855d-de9f-4397-bdec-7c5264449645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the extent for each tile.\n",
    "crs = grid_workflow.grid_spec.crs\n",
    "tile_ids = [tile[0] for tile in tiles.items()]\n",
    "tile_extents_geoms = [tile[1].geobox.extent.geom for tile in tiles.items()]\n",
    "tile_extents_gdf = gpd.GeoDataFrame(\n",
    "    {\"tile_id\": tile_ids, \"geometry\": tile_extents_geoms}, crs=crs\n",
    ")\n",
    "\n",
    "tile_extents_fp = os.path.join(output_directory, \"tile_boundaries.parquet\")\n",
    "\n",
    "tile_extents_gdf.to_parquet(tile_extents_fp)\n",
    "_log.info(f\"Tile boundaries written to {tile_extents_fp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37caa0c7-73fa-4c5c-8c89-b9c597aa4bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all parquet files for the first set of polygons.\n",
    "raster_polygon_paths = find_parquet_files(\n",
    "    path=polygons_from_thresholds_dir, pattern=\".*raster_polygons.*\"\n",
    ")\n",
    "_log.info(f\"Found {len(raster_polygon_paths)} parquet files for the raster polygons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8b2839-476e-45e1-9353-35f27bc3bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all polygons into a single GeoDataFrame.\n",
    "_log.info(\"Loading the raster polygons parquet files..\")\n",
    "raster_polygon_polygons_list = []\n",
    "for path in raster_polygon_paths:\n",
    "    gdf = gpd.read_parquet(path)\n",
    "    raster_polygon_polygons_list.append(gdf)\n",
    "\n",
    "raster_polygons = pd.concat(raster_polygon_polygons_list, ignore_index=True)\n",
    "_log.info(f\"Found {len(raster_polygons)} raster polygons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa2c1c1-b91c-4123-8001-45e26846d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_log.info(\"Merging raster waterbody polygons located at tile boundaries...\")\n",
    "raster_polygons_merged = merge_polygons_at_tile_boundaries(raster_polygons, tile_extents_gdf)\n",
    "# Drop the attributes column if it exists.\n",
    "raster_polygons_merged.drop(columns=[\"attribute\"], errors=\"ignore\", inplace=True)\n",
    "_log.info(\n",
    "    f\"Raster polygons count after merging polygons at tile boundaries {len(raster_polygons_merged)}.\"\n",
    ")\n",
    "\n",
    "_log.info(\"Writing raster polygons merged at tile boundaries to disk..\")\n",
    "raster_polygons_merged_fp = os.path.join(\n",
    "    output_directory, \"raster_polygons_merged_at_tile_boundaries.parquet\"\n",
    ")\n",
    "raster_polygons_merged.to_parquet(raster_polygons_merged_fp)\n",
    "_log.info(f\"Polygons written to {raster_polygons_merged_fp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca91459-e7ae-4c69-9b74-52b1d87b1e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete to conserve memeory\n",
    "del raster_polygons\n",
    "del tile_extents_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea283da0-cbd9-41ee-bacc-0529b5167c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the polygons by area.\n",
    "area_filtered_raster_polygons = filter_by_area(\n",
    "    raster_polygons_merged, min_polygon_size=min_polygon_size, max_polygon_size=max_polygon_size\n",
    ")\n",
    "area_filtered_raster_polygons.to_parquet(\n",
    "    os.path.join(output_directory, \"area_filtered_raster_polygons.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e0d9b2-ea43-4a5c-aba5-dd99c4b7729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "waterbodies_gdf = assign_unique_ids(polygons=area_filtered_raster_polygons)\n",
    "waterbodies_gdf = add_area_and_perimeter_attributes(polygons=waterbodies_gdf)\n",
    "waterbodies_gdf = add_timeseries_attribute(\n",
    "    polygons=waterbodies_gdf,\n",
    "    timeseries_directory=timeseries_directory,\n",
    "    region_code=\"af-south-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6cb3e4-c8de-4154-8d07-222c0fec33d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject to EPSG:4326\n",
    "waterbodies_gdf_4326 = waterbodies_gdf.to_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320e6d92-7f8a-4c8e-81f5-c724c6b8eb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to disk.\n",
    "write_waterbodies_to_file(\n",
    "    waterbodies_gdf=waterbodies_gdf_4326,\n",
    "    output_directory=output_directory,\n",
    "    file_name_prefix=file_name_prefix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa359c39-de0c-4ad6-ad88-dd516ad62972",
   "metadata": {},
   "outputs": [],
   "source": [
    "waterbodies_gdf_4326.to_parquet(os.path.join(output_directory, f\"{file_name_prefix}.parquet\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
