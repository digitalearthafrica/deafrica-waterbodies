{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdabd764-0960-4bcd-84f5-e007852c3869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "\n",
    "import click\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from deafrica_waterbodies.cli.logs import logging_setup\n",
    "from deafrica_waterbodies.filters import (\n",
    "    #filter_by_area,\n",
    "    filter_using_land_sea_mask,\n",
    "    filter_using_major_rivers_mask,\n",
    "    filter_using_urban_mask,\n",
    "    merge_primary_and_secondary_threshold_polygons,\n",
    "    split_large_polygons,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af67100-ff19-440f-b6e5-fe5724244ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the default AWS configurations for the Analysis Sandbox.\n",
    "# that are set in the environmnet variables.\n",
    "aws_default_config = {\n",
    "    # \"AWS_NO_SIGN_REQUEST\": \"YES\",\n",
    "    \"AWS_SECRET_ACCESS_KEY\": \"fake\",\n",
    "    \"AWS_ACCESS_KEY_ID\": \"fake\",\n",
    "}\n",
    "\n",
    "# To access public bucket, need to remove the AWS credentials in\n",
    "# the environment variables or the following error will occur.\n",
    "# PermissionError: The AWS Access Key Id you provided does not exist in our records.\n",
    "\n",
    "for key in aws_default_config.keys():\n",
    "    if key in os.environ:\n",
    "        del os.environ[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acc8246-b844-4e92-bc15-204bb54702e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 1\n",
    "output_directory = \"s3://deafrica-waterbodies-dev/test_out_dir/raster_processing/continental\"\n",
    "min_polygon_size = 4500  # 5 pixels\n",
    "max_polygon_size = math.inf\n",
    "land_sea_mask_fp = \"\"\n",
    "major_rivers_mask_fp = \"\"\n",
    "urban_mask_fp = \"\"\n",
    "handle_large_polygons = \"erode-dilate-v2\"\n",
    "pp_test_threshold = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a30849-c86a-4b8a-947c-cc12245d618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger.\n",
    "logging_setup(verbose=verbose)\n",
    "_log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1670f7c9-b5bf-4c41-b1c7-150da3728985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support pathlib paths.\n",
    "output_directory = str(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a0e9e0-2af9-473c-bdd2-65b4d64032f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raster polygons\n",
    "_log.info(\"Loading raster polygons...\")\n",
    "\n",
    "raster_polygons_fp = os.path.join(\n",
    "    output_directory, \"raster_polygons_merged_at_tile_boundaries.parquet\"\n",
    ")\n",
    "\n",
    "raster_polygons = gpd.read_parquet(raster_polygons_fp)\n",
    "\n",
    "_log.info(f\"Raster polygons count {len(raster_polygons)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4356fce-0ce4-4727-9076-eaaba6d6db08",
   "metadata": {},
   "source": [
    "## To Do\n",
    "\n",
    "1. Run the existing \"erode-dilate-v2\" splitting method on polygons that are larger than 10^8 in area. The code for this is below.\n",
    "2. Fix holes in large polygons -- consider isolating to the largest polygons only. You can see an example of the issue over Lake Victoria. This stack overflow page might be of use: https://stackoverflow.com/questions/63317410/how-to-fill-holes-in-multi-polygons-created-when-dissolving-geodataframe-with-ge\n",
    "3. Remove polygons that don't meet the area requirements.\n",
    "4. Ensure the polygons have all the required attributes (area, perimeter, timeseries csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a66e88-c7de-45e4-84ab-7f025592c6cb",
   "metadata": {},
   "source": [
    "### Run split on large polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cf3ada-4911-4340-a12e-1cabd284f4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "larger_10tothe8 = raster_polygons.loc[raster_polygons.area >= 10**8, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea668664-51e3-4dd5-9d7c-92897361391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_polygons_handled = split_large_polygons(\n",
    "    waterbody_polygons=larger_10tothe8, pp_thresh=0.005, method=\"erode-dilate-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386962d9-2314-4a37-8225-dceb965632c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do: drop the selected polygons from the continental dataset \n",
    "# and add back in the newly split polygons. Export to s3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e74ac9f-30c1-4650-8a4e-704135c97ea5",
   "metadata": {},
   "source": [
    "### Fix holes in large polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf88bbbb-d173-4240-9f17-33b7c1503f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do: investigate geopandas approach, otherwise, could do this in GIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe252e1c-c35a-4e31-ad59-021721111460",
   "metadata": {},
   "source": [
    "### Remove small polygons\n",
    "\n",
    "Have redefined the function in this notebook to work on the combined raster polygons. The original function could be updated in the filters.py file once we know it's working as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e22917-0bf3-475a-a975-d665ae54d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_area(\n",
    "    raster_polygons: gpd.GeoDataFrame | None,\n",
    "    min_polygon_size: float = 4500,\n",
    "    max_polygon_size: float = math.inf,\n",
    ") -> tuple[gpd.GeoDataFrame, gpd.GeoDataFrame]:\n",
    "    \"\"\"\n",
    "    Filter the primary and secondary threshold polygons using the minimum and\n",
    "    maximum area.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raster_polygons : gpd.GeoDataFrame\n",
    "    secondary_threshold_polygons : gpd.GeoDataFrame\n",
    "    min_polygon_size : float, optional\n",
    "        Minimum area of a waterbody polygon to be included in the output polygons, by default 4500\n",
    "    max_polygon_size : float, optional\n",
    "        Maximum area of a waterbody polygon to be included in the output polygons, by default math.inf\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[gpd.GeoDataFrame, gpd.GeoDataFrame]:\n",
    "        The area filtered primary threshold polygons and the area filtered\n",
    "        secondary threshold polygons.\n",
    "    \"\"\"\n",
    "\n",
    "    if raster_polygons is not None:\n",
    "        _log.info(\n",
    "            f\"Filtering primary threshold polygons by minimum area {min_polygon_size} and max area {max_polygon_size}...\"\n",
    "        )\n",
    "\n",
    "        raster_polygons[\"area\"] = pd.to_numeric(raster_polygons.area)\n",
    "        area_filtered_raster_polygons = raster_polygons.loc[\n",
    "            (\n",
    "                (raster_polygons[\"area\"] > min_polygon_size)\n",
    "                & (raster_polygons[\"area\"] <= max_polygon_size)\n",
    "            )\n",
    "        ]\n",
    "        area_filtered_raster_polygons.reset_index(drop=True, inplace=True)\n",
    "        _log.info(\n",
    "            f\"Filtered out {len(raster_polygons) - len(area_filtered_raster_polygons)} primary threshold polygons.\"\n",
    "        )\n",
    "    else:\n",
    "        area_filtered_raster_polygons = None\n",
    "\n",
    "    return area_filtered_raster_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a79021-4379-41cf-973d-5d9a593786bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do: Filter final cleaned polygons by area and export parquet to s3\n",
    "\n",
    "area_filtered_raster_polygons = filter_by_area(\n",
    "    raster_polygons, \n",
    "    min_polygon_size=min_polygon_size,\n",
    "    max_polygon_size=max_polygon_size,\n",
    ")\n",
    "\n",
    "area_filtered_raster_polygons_fp = os.path.join(\n",
    "    output_directory, \"area_filtered_raster_polygons.parquet\"\n",
    ")\n",
    "area_filtered_raster_polygons.to_parquet(area_filtered_raster_polygons_fp)\n",
    "_log.info(f\"Area filtered primary threshold polygons written to {area_filtered_raster_polygons_fp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35e301e-8591-4418-a91f-747952d953f0",
   "metadata": {},
   "source": [
    "### Add required attributes and then export to s3\n",
    "Once the file is generated with the necessary attributes, ask Leon to upload it to the GeoServer (replace the existing senegal basin file, keeping the same name). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54410f6f-3ff7-457a-9e56-156128815a74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
