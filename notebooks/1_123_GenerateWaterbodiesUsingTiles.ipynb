{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0a31b-28d9-41d4-b59b-4ccb900e2528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import click\n",
    "import datacube\n",
    "import fsspec\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from deafrica_waterbodies.cli.logs import logging_setup\n",
    "from deafrica_waterbodies.io import (\n",
    "    check_dir_exists,\n",
    "    check_file_exists,\n",
    "    check_if_s3_uri,\n",
    "    find_parquet_files,\n",
    ")\n",
    "from deafrica_waterbodies.make_polygons import (\n",
    "    check_wetness_thresholds,\n",
    "    get_polygons_from_tile,\n",
    "    merge_polygons_at_tile_boundaries\n",
    ")\n",
    "from deafrica_waterbodies.tiling import (\n",
    "    filter_tiles,\n",
    "    get_tiles_ids,\n",
    "    tile_wofs_ls_summary_alltime,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c574ee-39c4-4931-b807-5d3f97900cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# These are the default AWS configurations for the Analysis Sandbox.\n",
    "# that are set in the environmnet variables.\n",
    "aws_default_config = {\n",
    "    # \"AWS_NO_SIGN_REQUEST\": \"YES\",\n",
    "    \"AWS_SECRET_ACCESS_KEY\": \"fake\",\n",
    "    \"AWS_ACCESS_KEY_ID\": \"fake\",\n",
    "}\n",
    "\n",
    "# To access public bucket, need to remove the AWS credentials in\n",
    "# the environment variables or the following error will occur.\n",
    "# PermissionError: The AWS Access Key Id you provided does not exist in our records.\n",
    "\n",
    "for key in aws_default_config.keys():\n",
    "    if key in os.environ:\n",
    "        del os.environ[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e50efa3-b5ba-44b3-b164-608d17e6413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 1\n",
    "\n",
    "aoi_vector_file = \"data/SenegalBasin.geojson\"\n",
    "tile_size_factor = 4\n",
    "num_workers = 16\n",
    "\n",
    "primary_threshold: float = 0.1\n",
    "secondary_threshold: float = 0.05\n",
    "minimum_valid_observations: int = 128\n",
    "output_directory = \"s3://deafrica-waterbodies-dev/test_out_dir/0-0-1/shapefile4\"\n",
    "overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dfbcc2-fd39-4900-815c-09a11c448b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger.\n",
    "logging_setup(verbose=verbose)\n",
    "_log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0742d7-6ca2-4286-9313-3efda5173f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support pathlib Paths.\n",
    "aoi_vector_file = str(aoi_vector_file)\n",
    "output_directory = str(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db4ad8-7193-47e4-a4b4-44085924a793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to use when loading datasets.\n",
    "dask_chunks = {\"x\": 3200, \"y\": 3200, \"time\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a0ca66-2695-42c8-968a-523151d514c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the area of interest as a GeoDataFrame.\n",
    "if aoi_vector_file is not None:\n",
    "    try:\n",
    "        aoi_gdf = gpd.read_file(aoi_vector_file)\n",
    "    except Exception as error:\n",
    "        _log.exception(f\"Could not read the file {aoi_vector_file}\")\n",
    "        raise error\n",
    "else:\n",
    "    aoi_gdf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b4349-4d9c-4e55-aae0-b661ccde8da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tile the wofs_ls_summary_alltime product.\n",
    "tiles, grid_workflow = tile_wofs_ls_summary_alltime(tile_size_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f134e90d-9c9a-47ca-86da-687846f2568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the tiles to the area of interest.\n",
    "filtered_tile_ids = filter_tiles(tiles, aoi_gdf, num_workers)\n",
    "filtered_tiles = {k: v for k, v in tiles.items() if k in filtered_tile_ids}\n",
    "\n",
    "print(len(filtered_tiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73816db0-7445-423a-a616-9966187a0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to write generated waterbody polygons to.\n",
    "polygons_from_thresholds_dir = os.path.join(output_directory, \"polygons_from_thresholds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a0c8b-9bc5-469e-8bc2-9a2a0588265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the filesystem to use.\n",
    "if check_if_s3_uri(polygons_from_thresholds_dir):\n",
    "    fs = fsspec.filesystem(\"s3\")\n",
    "else:\n",
    "    fs = fsspec.filesystem(\"file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe40837-f598-4d7c-a3fd-6c1deb2b0589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the directory exists. If it does not, create it.\n",
    "if not check_dir_exists(polygons_from_thresholds_dir):\n",
    "    fs.mkdirs(polygons_from_thresholds_dir, exist_ok=True)\n",
    "    _log.info(f\"Created directory {polygons_from_thresholds_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c85a8d3-9543-4a57-90b8-3ac5e6cae71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the wetness thresholds have been set correctly.\n",
    "minimum_wet_thresholds = [secondary_threshold, primary_threshold]\n",
    "_log.info(check_wetness_thresholds(minimum_wet_thresholds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f37f02-ce60-43c9-9dc4-4c5298b15a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the first set of primary and secondary threhsold polygons for each of the tiles.\n",
    "for tile in filtered_tiles.items():\n",
    "    tile_id = tile[0]\n",
    "    primary_threshold_polygons_fp = os.path.join(\n",
    "        polygons_from_thresholds_dir, f\"{tile_id[0]}_{tile_id[1]}_primary_threshold_polygons.parquet\"\n",
    "    )\n",
    "    secondary_threshold_polygons_fp = os.path.join(\n",
    "        polygons_from_thresholds_dir, f\"{tile_id[0]}_{tile_id[1]}_secondary_threshold_polygons.parquet\"\n",
    "    )\n",
    "\n",
    "    if not overwrite:\n",
    "        _log.info(f\"Checking existence of {primary_threshold_polygons_fp} and {secondary_threshold_polygons_fp}\")\n",
    "        exists = check_file_exists(primary_threshold_polygons_fp) and check_file_exists(secondary_threshold_polygons_fp)\n",
    "\n",
    "    if overwrite or not exists:\n",
    "        (\n",
    "            primary_threshold_polygons,\n",
    "            secondary_threshold_polygons,\n",
    "        ) = get_polygons_from_tile(\n",
    "            tile=tile,\n",
    "            grid_workflow=grid_workflow,\n",
    "            dask_chunks=dask_chunks,\n",
    "            min_valid_observations=minimum_valid_observations,\n",
    "            primary_threshold=primary_threshold,\n",
    "            secondary_threshold=secondary_threshold,\n",
    "        )\n",
    "        # Write the polygons to parquet files.\n",
    "        primary_threshold_polygons.to_parquet(primary_threshold_polygons_fp)\n",
    "        secondary_threshold_polygons.to_parquet(secondary_threshold_polygons_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d552b8-32fd-427c-835b-92245f627d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the extents for each tile.\n",
    "crs = grid_workflow.grid_spec.crs\n",
    "filtered_tiles_extents_geoms = [tile[1].geobox.extent.geom for tile in filtered_tiles.items()]\n",
    "filtered_tiles_extents_gdf = gpd.GeoDataFrame(geometry=filtered_tiles_extents_geoms, crs=crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0c48e-feeb-47c0-a13b-fbe3ee940ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all parquet files for the primary threshold.\n",
    "primary_threshold_polygons_paths = find_parquet_files(path=polygons_from_thresholds_dir, pattern=\".*primary.*\")\n",
    "_log.info(f\"Found {len(primary_threshold_polygons_paths)} parquet files for the primary threshold polygons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeb0c77-93d9-4cc6-a2d2-2542875abf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the primary threshold polygons into a single GeoDataFrame.\n",
    "_log.info(\"Loading the primary threshold polygons parquet files..\")\n",
    "primary_threshold_polygons_list = []\n",
    "for path in primary_threshold_polygons_paths:\n",
    "    gdf = gpd.read_parquet(path)\n",
    "    primary_threshold_polygons_list.append(gdf)\n",
    "\n",
    "primary_threshold_polygons = pd.concat(primary_threshold_polygons_list, ignore_index=True)\n",
    "_log.info(f\"Found {len(primary_threshold_polygons)} primary threshold polygons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3fa531-851c-47f9-a9d4-87647b130da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_log.info(\"Merging primary threshold waterbody polygons located at tile boundaries...\")\n",
    "primary_threshold_polygons_merged = merge_polygons_at_tile_boundaries(\n",
    "    primary_threshold_polygons, filtered_tiles_extents_gdf\n",
    ")\n",
    "_log.info(f\"Primary threshold polygons count {len(primary_threshold_polygons_merged)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70430dbd-8ef5-46cb-8def-c9cf5c0dda35",
   "metadata": {},
   "outputs": [],
   "source": [
    "_log.info(\"Writing primary threshold polygons merged at tile boundaries to disk..\")\n",
    "primary_threshold_polygons_output_fp = os.path.join(\n",
    "    output_directory, \"primary_threshold_polygons_merged_at_tile_boundaries.parquet\"\n",
    ")\n",
    "\n",
    "primary_threshold_polygons_merged.to_parquet(primary_threshold_polygons_output_fp)\n",
    "_log.info(f\"Polygons written to {primary_threshold_polygons_output_fp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70440491-216a-42d6-b26e-c943b918a6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all parquet files for the secondary threshold.\n",
    "secondary_threshold_polygons_paths = find_parquet_files(path=polygons_from_thresholds_dir, pattern=\".*secondary.*\")\n",
    "_log.info(f\"Found {len(secondary_threshold_polygons_paths)} parquet files for the secondary threshold polygons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096b45e5-caf9-4df4-8d36-b96cfb733d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the secondary threshold polygons into a single GeoDataFrame.\n",
    "_log.info(\"Loading the secondary threshold polygons parquet files...\")\n",
    "secondary_threshold_polygons_list = []\n",
    "for path in secondary_threshold_polygons_paths:\n",
    "    gdf = gpd.read_parquet(path)\n",
    "    secondary_threshold_polygons_list.append(gdf)\n",
    "\n",
    "secondary_threshold_polygons = pd.concat(secondary_threshold_polygons_list, ignore_index=True)\n",
    "_log.info(f\"Found {len(secondary_threshold_polygons)} secondary threshold polygons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b010dca0-9357-4a94-936c-b36e3500e7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_log.info(\"Merging secondary threshold waterbody polygons located at dataset/scene boundaries...\")\n",
    "secondary_threshold_polygons_merged = merge_polygons_at_tile_boundaries(\n",
    "    secondary_threshold_polygons, filtered_tiles_extents_gdf\n",
    ")\n",
    "_log.info(f\"Secondary threshold polygons count {len(secondary_threshold_polygons_merged)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703dc6e4-8ce0-48a3-851b-22355daed66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_log.info(\"Writing secondary threshold polygons merged at tile boundaries to disk..\")\n",
    "secondary_threshold_polygons_output_fp = os.path.join(\n",
    "    output_directory, \"secondary_threshold_polygons_merged_at_ds_boundaries.parquet\"\n",
    ")\n",
    "\n",
    "secondary_threshold_polygons_merged.to_parquet(secondary_threshold_polygons_output_fp)\n",
    "\n",
    "_log.info(f\"Polygons written to {secondary_threshold_polygons_output_fp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
