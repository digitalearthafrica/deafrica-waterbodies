{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdabd764-0960-4bcd-84f5-e007852c3869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "\n",
    "import deafrica_waterbodies.filters\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from deafrica_waterbodies.cli.logs import logging_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3af67100-ff19-440f-b6e5-fe5724244ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# These are the default AWS configurations for the Analysis Sandbox.\n",
    "# that are set in the environmnet variables.\n",
    "aws_default_config = {\n",
    "    # \"AWS_NO_SIGN_REQUEST\": \"YES\",\n",
    "    \"AWS_SECRET_ACCESS_KEY\": \"fake\",\n",
    "    \"AWS_ACCESS_KEY_ID\": \"fake\",\n",
    "}\n",
    "\n",
    "# To access public bucket, need to remove the AWS credentials in\n",
    "# the environment variables or the following error will occur.\n",
    "# PermissionError: The AWS Access Key Id you provided does not exist in our records.\n",
    "\n",
    "for key in aws_default_config.keys():\n",
    "    if key in os.environ:\n",
    "        del os.environ[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7acc8246-b844-4e92-bc15-204bb54702e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 1\n",
    "output_directory = \"s3://deafrica-waterbodies-dev/test_out_dir\"\n",
    "min_polygon_size = 4500  # 5 pixels\n",
    "max_polygon_size = math.inf\n",
    "land_sea_mask_fp = \"GOaS_v1_20211214/goas_v01.shp\"\n",
    "major_rivers_mask_fp = \"\"\n",
    "urban_mask_fp = \"\"\n",
    "handle_large_polygons = \"erode-dilate-v2\"\n",
    "pp_test_threshold = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32a30849-c86a-4b8a-947c-cc12245d618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger.\n",
    "logging_setup(verbose=verbose)\n",
    "_log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1670f7c9-b5bf-4c41-b1c7-150da3728985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support pathlib paths.\n",
    "output_directory = str(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1a0e9e0-2af9-473c-bdd2-65b4d64032f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-04 20:32:17,363] {7015612.py:2} INFO - Loading primary and secondary threshold polygons...\n",
      "[2023-10-04 20:32:18,241] {7015612.py:13} INFO - Primary threshold polygons count 42588.\n",
      "[2023-10-04 20:32:18,242] {7015612.py:14} INFO - Secondary threshold polygons count 81450.\n"
     ]
    }
   ],
   "source": [
    "# Load the primary and secondary threshold polygons\n",
    "_log.info(\"Loading primary and secondary threshold polygons...\")\n",
    "\n",
    "primary_threshold_polygons_fp = os.path.join(\n",
    "    output_directory, \"primary_threshold_polygons_merged_at_ds_boundaries.parquet\"\n",
    ")\n",
    "secondary_threshold_polygons_fp = os.path.join(\n",
    "    output_directory, \"secondary_threshold_polygons_merged_at_ds_boundaries.parquet\"\n",
    ")\n",
    "primary_threshold_polygons = gpd.read_parquet(primary_threshold_polygons_fp)\n",
    "secondary_threshold_polygons = gpd.read_parquet(secondary_threshold_polygons_fp)\n",
    "\n",
    "_log.info(f\"Primary threshold polygons count {len(primary_threshold_polygons)}.\")\n",
    "_log.info(f\"Secondary threshold polygons count {len(secondary_threshold_polygons)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d08d600-b0ab-41c8-a2fa-43a6015609d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert primary_threshold_polygons.crs == secondary_threshold_polygons.crs\n",
    "crs = primary_threshold_polygons.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b38544e-1383-4339-8ad6-3c08ca40bf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-04 20:32:18,252] {676914410.py:1} INFO - Filtering primary threshold polygons by minimum area 4500 and max area inf...\n",
      "[2023-10-04 20:32:18,264] {676914410.py:7} INFO - Filtered out 30951 primary threshold polygons\n",
      "[2023-10-04 20:32:18,583] {676914410.py:13} INFO - Area filtered primary threshold polygons written to s3://deafrica-waterbodies-dev/test_out_dir/area_filtered_primary_threshold_polygons.parquet\n"
     ]
    }
   ],
   "source": [
    "_log.info(f\"Filtering primary threshold polygons by minimum area {min_polygon_size} and max area {max_polygon_size}...\")\n",
    "\n",
    "primary_threshold_polygons[\"area\"] = pd.to_numeric(primary_threshold_polygons.area)\n",
    "area_filtered_primary_threshold_polygons = primary_threshold_polygons.loc[\n",
    "    ((primary_threshold_polygons[\"area\"] > min_polygon_size) & (primary_threshold_polygons[\"area\"] <= max_polygon_size))\n",
    "]\n",
    "_log.info(\n",
    "    f\"Filtered out {len(primary_threshold_polygons) - len(area_filtered_primary_threshold_polygons)} primary threshold polygons\"\n",
    ")\n",
    "\n",
    "area_filtered_primary_threshold_polygons_fp = os.path.join(output_directory, \"area_filtered_primary_threshold_polygons.parquet\")\n",
    "area_filtered_primary_threshold_polygons.to_parquet(area_filtered_primary_threshold_polygons_fp)\n",
    "_log.info(f\"Area filtered primary threshold polygons written to {area_filtered_primary_threshold_polygons_fp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6297486-33c6-43d2-ba56-4d6cd9583164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-04 20:32:18,589] {45407760.py:1} INFO - Filtering secondary threshold polygons by max area inf...\n",
      "[2023-10-04 20:32:18,612] {45407760.py:7} INFO - Filtered out 0 secondary threshold polygons\n",
      "[2023-10-04 20:32:19,137] {45407760.py:13} INFO - Area filtered secondary threshold polygons written to s3://deafrica-waterbodies-dev/test_out_dir/area_filtered_secondary_threshold_polygons.parquet\n"
     ]
    }
   ],
   "source": [
    "_log.info(f\"Filtering secondary threshold polygons by max area {max_polygon_size}...\")\n",
    "\n",
    "secondary_threshold_polygons[\"area\"] = pd.to_numeric(secondary_threshold_polygons.area)\n",
    "area_filtered_secondary_threshold_polygons = secondary_threshold_polygons.loc[\n",
    "    secondary_threshold_polygons[\"area\"] <= max_polygon_size\n",
    "]\n",
    "_log.info(\n",
    "    f\"Filtered out {len(secondary_threshold_polygons) - len(area_filtered_secondary_threshold_polygons)} secondary threshold polygons\"\n",
    ")\n",
    "\n",
    "area_filtered_secondary_threshold_polygons_fp = os.path.join(output_directory, \"area_filtered_secondary_threshold_polygons.parquet\")\n",
    "area_filtered_secondary_threshold_polygons.to_parquet(area_filtered_secondary_threshold_polygons_fp)\n",
    "_log.info(f\"Area filtered secondary threshold polygons written to {area_filtered_secondary_threshold_polygons_fp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa18c51c-3e1a-44a9-80ce-17fcce0422fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-04 20:32:19,144] {2040202294.py:2} INFO - Filtering out ocean polygons from the primary and secondary threshold waterbody polygons.\n",
      "[2023-10-04 20:33:02,727] {2040202294.py:10} INFO - Filtered out 107 primary threshold polygons.\n",
      "[2023-10-04 20:33:03,067] {2040202294.py:14} INFO - Ocean filtered primary threshold polygons written to s3://deafrica-waterbodies-dev/test_out_dir/inland_primary_threshold_polygons.parquet\n"
     ]
    }
   ],
   "source": [
    "if land_sea_mask_fp:\n",
    "    _log.info(\"Filtering out ocean polygons from the primary and secondary threshold waterbody polygons.\")\n",
    "    try:\n",
    "        land_sea_mask = gpd.read_file(land_sea_mask_fp).to_crs(crs)\n",
    "    except Exception as error:\n",
    "        _log.exception(f\"Could not read file {land_sea_mask}\")\n",
    "        raise error\n",
    "    else:\n",
    "        inland_primary_threshold_polygons, _ = deafrica_waterbodies.filters.filter_geodataframe_by_intersection(area_filtered_primary_threshold_polygons, land_sea_mask, invert_mask=True)\n",
    "        _log.info(f\"Filtered out {len(area_filtered_primary_threshold_polygons) - len(inland_primary_threshold_polygons)} primary threshold polygons.\")\n",
    "        \n",
    "        inland_primary_threshold_polygons_fp =  os.path.join(output_directory, \"inland_primary_threshold_polygons.parquet\")\n",
    "        inland_primary_threshold_polygons.to_parquet(inland_primary_threshold_polygons_fp)\n",
    "        _log.info(f\"Ocean filtered primary threshold polygons written to {inland_primary_threshold_polygons_fp}\")\n",
    "        \n",
    "        inland_secondary_threshold_polygons, _ = deafrica_waterbodies.filters.filter_geodataframe_by_intersection(area_filtered_secondary_threshold_polygons, land_sea_mask, invert_mask=True)\n",
    "        _log.info(f\"Filtered out {len(area_filtered_secondary_threshold_polygons) - len(inland_secondary_threshold_polygons)} secondary threshold polygons.\")\n",
    "        \n",
    "        inland_secondary_threshold_polygons_fp =  os.path.join(output_directory, \"inland_secondary_threshold_polygons.parquet\")\n",
    "        inland_secondary_threshold_polygons.to_parquet(inland_secondary_threshold_polygons_fp)\n",
    "        _log.info(f\"Ocean filtered secondary threshold polygons written to {inland_secondary_threshold_polygons_fp}\")\n",
    "        \n",
    "else:\n",
    "    _log.info(\"Skipping filtering out ocean polygons step.\")\n",
    "    inland_primary_threshold_polygons =  area_filtered_primary_threshold_polygons\n",
    "    inland_secondary_threshold_polygons = area_filtered_secondary_threshold_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f52b2bf-5fda-4eec-bddd-9603fb3775dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if urban_mask_fp:\n",
    "    _log.info(\"Filtering out CBDs polygons from the primary threshold polygons...\")\n",
    "    try:\n",
    "        urban_mask = gpd.read_file(urban_mask_fp).to_crs(crs)\n",
    "    except Exception as error:\n",
    "        _log.exception(f\"Could not read file {urban_mask_fp}\")\n",
    "        raise error\n",
    "    else:\n",
    "        cbd_filtered_primary_threshold_polygons, _ = deafrica_waterbodies.filters.filter_geodataframe_by_intersection(\n",
    "            inland_primary_threshold_polygons,\n",
    "            urban_mask)\n",
    "        _log.info(f\"Filtered out {len(inland_primary_threshold_polygons) - len(cbd_filtered_primary_threshold_polygons)} primary threshold polygons.\")\n",
    "        \n",
    "        cbd_filtered_primary_threshold_polygons_fp =  os.path.join(output_directory, \"cbd_filtered_primary_threshold_polygons.parquet\")\n",
    "        cbd_filtered_primary_threshold_polygons.to_parquet(cbd_filtered_primary_threshold_polygons_fp)\n",
    "        _log.info(f\"CBDs filtered primary threshold polygons written to {cbd_filtered_primary_threshold_polygons_fp}\")\n",
    "        \n",
    "else:\n",
    "    _log.info(\"Skipping filtering out CBDs polygons step.\")\n",
    "    cbd_filtered_primary_threshold_polygons = inland_primary_threshold_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65e3f21-228c-4856-b065-50157421bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Merge the primary and secondary threshold polygons.\n",
    "_log.info(\"Merging the primary threshold and secondary threshold polygons...\")\n",
    "merged_polygons = deafrica_waterbodies.filters.merge_primary_and_secondary_threshold_polygons(\n",
    "    primary_threshold_polygons=cbd_filtered_primary_threshold_polygons,\n",
    "    secondary_threshold_polygons=inland_secondary_threshold_polygons)\n",
    "_log.info(f\"Total waterbody polygons count after merge: {len(merged_polygons)}.\")\n",
    "\n",
    "merged_polygons_fp = os.path.join(output_directory, \"merged_polygons.parquet\")\n",
    "merged_polygons.to_parquet(merged_polygons_fp)\n",
    "_log.info(f\"Merged waterbody polygons written to {merged_polygons_fp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c4dc2a-e6d6-46f2-becf-912802d68344",
   "metadata": {},
   "outputs": [],
   "source": [
    "if major_rivers_mask_fp:\n",
    "    _log.info(\"Filtering out major rivers polygons from the waterbody polygons...\")\n",
    "    try:\n",
    "        major_rivers = gpd.read_file(major_rivers_mask_fp).to_crs(crs)\n",
    "    except Exception as error:\n",
    "        _log.exception(f\"Could not read file {major_rivers_mask_fp}\")\n",
    "        raise error\n",
    "    else:\n",
    "        major_rivers_filtered_polygons, _ = deafrica_waterbodies.filters.filter_geodataframe_by_intersection(\n",
    "            merged_polygons,\n",
    "            major_rivers)\n",
    "        _log.info(f\"Filtered out {len(merged_polygons) - len(major_rivers_filtered_polygons)} waterbody polygons.\")\n",
    "        \n",
    "        major_rivers_filtered_polygons_fp =  os.path.join(output_directory, \"major_rivers_filtered_polygons.parquet\")\n",
    "        major_rivers_filtered_polygons.to_parquet(major_rivers_filtered_polygons_fp)\n",
    "        _log.info(f\"Major rivers filtered polygons written to {major_rivers_filtered_polygons_fp}\")\n",
    "        \n",
    "else:\n",
    "    _log.info(\"Skipping filtering out major rivers polygons step.\")\n",
    "    major_rivers_filtered_polygons = merged_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f56b2e-b820-41cb-a8ef-5ba96291d15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle large polygons.\n",
    "_log.info(\"Splitting large polygons...\")\n",
    "large_polygons_handled = deafrica_waterbodies.filters.split_large_polygons(\n",
    "    input_gdf=major_rivers_filtered_polygons, pp_thresh=pp_test_threshold, method=handle_large_polygons\n",
    ")\n",
    "_log.info(f\"Waterbody polygons count after splitting large polygons {len(large_polygons_handled)}\")\n",
    "\n",
    "large_polygons_handled_fp = os.path.join(output_directory, \"large_polygons_handled.parquet\")\n",
    "large_polygons_handled.to_parquet(large_polygons_handled_fp)\n",
    "_log.info(f\"Waterbodies with large polygons handled written to {large_polygons_handled_fp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
