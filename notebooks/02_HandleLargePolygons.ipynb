{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdabd764-0960-4bcd-84f5-e007852c3869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import logging\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "    \n",
    "from deafrica_waterbodies.cli.logs import logging_setup\n",
    "from deafrica_waterbodies.filters import split_large_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3af67100-ff19-440f-b6e5-fe5724244ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# These are the default AWS configurations for the Analysis Sandbox.\n",
    "# that are set in the environmnet variables.\n",
    "aws_default_config = {\n",
    "    # \"AWS_NO_SIGN_REQUEST\": \"YES\",\n",
    "    \"AWS_SECRET_ACCESS_KEY\": \"fake\",\n",
    "    \"AWS_ACCESS_KEY_ID\": \"fake\",\n",
    "}\n",
    "\n",
    "# To access public bucket, need to remove the AWS credentials in\n",
    "# the environment variables or the following error will occur.\n",
    "# PermissionError: The AWS Access Key Id you provided does not exist in our records.\n",
    "\n",
    "for key in aws_default_config.keys():\n",
    "    if key in os.environ:\n",
    "        del os.environ[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7acc8246-b844-4e92-bc15-204bb54702e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 1\n",
    "output_directory = \"s3://deafrica-waterbodies-dev/test_out_dir/raster_processing/continental\"\n",
    "#output_directory = \"s3://deafrica-waterbodies-dev/0-0-1/shapefile/\"\n",
    "handle_large_polygons = \"erode-dilate-v2\"\n",
    "pp_test_threshold = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32a30849-c86a-4b8a-947c-cc12245d618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger.\n",
    "logging_setup(verbose=verbose)\n",
    "_log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1670f7c9-b5bf-4c41-b1c7-150da3728985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support pathlib paths.\n",
    "output_directory = str(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1a0e9e0-2af9-473c-bdd2-65b4d64032f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-17 20:18:00,846] {4168478290.py:2} INFO - Loading raster polygons...\n",
      "[2023-10-17 20:18:09,829] {4168478290.py:13} INFO - Raster polygons count 1075799.\n"
     ]
    }
   ],
   "source": [
    "# Load the raster polygons\n",
    "_log.info(\"Loading raster polygons...\")\n",
    "\n",
    "raster_polygons_fp = os.path.join(\n",
    "    output_directory, \"raster_polygons_merged_at_tile_boundaries.parquet\"\n",
    ")\n",
    "\n",
    "raster_polygons = gpd.read_parquet(raster_polygons_fp)\n",
    "\n",
    "# Drop the attributes column.\n",
    "raster_polygons.drop(columns=[\"attribute\"], errors=\"ignore\", inplace=True)\n",
    "\n",
    "_log.info(f\"Raster polygons count {len(raster_polygons)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a66e88-c7de-45e4-84ab-7f025592c6cb",
   "metadata": {},
   "source": [
    "### Run split on large polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55cf3ada-4911-4340-a12e-1cabd284f4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-17 20:18:30,496] {434086015.py:4} INFO - Count for polygons larger than 100000000 m2: 239\n"
     ]
    }
   ],
   "source": [
    "# Identify the large polygons.\n",
    "large_polygons_threshold = 10**8\n",
    "large_polygons = gpd.GeoDataFrame(data=raster_polygons.loc[raster_polygons.area >= large_polygons_threshold])\n",
    "_log.info(f\"Count for polygons larger than {large_polygons_threshold} m2: {len(large_polygons)}\")\n",
    "large_polygons.to_parquet(os.path.join(output_directory, \"large_polygons.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d2f5aae-5c16-421f-94f5-bc5c30866dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-17 20:18:32,621] {2675327616.py:4} INFO - 239 large polygons removed from raster polygons.\n"
     ]
    }
   ],
   "source": [
    "# Remove the large polygons from the raster polygons.\n",
    "large_polygons_idx = large_polygons.index.values\n",
    "raster_polygons_large_removed = raster_polygons.drop(index=large_polygons_idx)\n",
    "_log.info(f\"{len(raster_polygons) - len(raster_polygons_large_removed)} large polygons removed from raster polygons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea668664-51e3-4dd5-9d7c-92897361391b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-17 20:19:00,107] {filters.py:622} INFO - Splitting large polygons using the `erode-dilate-v2` method, using the threshold 0.005.\n",
      "[2023-10-17 20:19:00,192] {filters.py:507} INFO - Splitting 73 polygons.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Split the large polygons.\n",
    "large_polygons_handled = split_large_polygons(waterbody_polygons=large_polygons, pp_test_threshold=pp_test_threshold, method=handle_large_polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae891373-f157-44df-b47c-d3265e27c5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add back in the newly split polygons.\n",
    "raster_polygons_large_poly_split = pd.concat([raster_polygons_large_removed, large_polygons_handled], ignore_index=True)\n",
    "_log.info(f\"Polygon count after handling large polygons {len(raster_polygons_large_poly_split)}.\")\n",
    "raster_polygons_large_poly_split.to_parquet(os.path.join(output_directory, \"raster_polygons_large_polygons_handled.parquet\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
