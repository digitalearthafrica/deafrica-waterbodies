{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3347ff15-1868-4c84-a330-d21b790c5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import click\n",
    "import datacube\n",
    "import fsspec\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from deafrica_waterbodies.cli.logs import logging_setup\n",
    "from deafrica_waterbodies.io import (\n",
    "    check_dir_exists,\n",
    "    check_file_exists,\n",
    "    check_if_s3_uri,\n",
    "    find_parquet_files,\n",
    ")\n",
    "from deafrica_waterbodies.make_polygons import (\n",
    "    set_wetness_thresholds,\n",
    "    process_raster_polygons,\n",
    "    merge_polygons_at_tile_boundaries\n",
    ")\n",
    "from deafrica_waterbodies.tiling import (\n",
    "    filter_tiles,\n",
    "    get_tiles_ids,\n",
    "    tile_wofs_ls_summary_alltime,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c574ee-39c4-4931-b807-5d3f97900cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the default AWS configurations for the Analysis Sandbox.\n",
    "# that are set in the environmnet variables.\n",
    "aws_default_config = {\n",
    "    # \"AWS_NO_SIGN_REQUEST\": \"YES\",\n",
    "    \"AWS_SECRET_ACCESS_KEY\": \"fake\",\n",
    "    \"AWS_ACCESS_KEY_ID\": \"fake\",\n",
    "}\n",
    "\n",
    "# To access public bucket, need to remove the AWS credentials in\n",
    "# the environment variables or the following error will occur.\n",
    "# PermissionError: The AWS Access Key Id you provided does not exist in our records.\n",
    "\n",
    "for key in aws_default_config.keys():\n",
    "    if key in os.environ:\n",
    "        del os.environ[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e50efa3-b5ba-44b3-b164-608d17e6413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 1\n",
    "\n",
    "# aoi_vector_file = None\n",
    "aoi_vector_file = \"data/SenegalBasin.geojson\"\n",
    "tile_size_factor = 4\n",
    "num_workers = 16\n",
    "\n",
    "detection_threshold: float = 0.1\n",
    "extent_threshold: float = 0.05\n",
    "min_valid_observations: int = 128\n",
    "# output_directory = \"s3://deafrica-waterbodies-dev/test_out_dir/raster_processing/continental\"\n",
    "output_directory = \"s3://deafrica-waterbodies-dev/0-0-1/shapefile/\"\n",
    "overwrite = False\n",
    "land_sea_mask_fp = \"data/af_msk_3s.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98a89fc-74fe-483b-89d5-b268c175d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "def filter_hydrosheds_land_mask(hydrosheds_land_mask: xr.DataArray) -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    Function to filter the HydroSHEDs Land Mask into a boolean mask.\n",
    "    \"\"\"\n",
    "    # Indicator values: 1 = land, 2 = ocean sink, 3 = inland sink, 255 is no data.\n",
    "    boolean_mask = (hydrosheds_land_mask != 255) & (hydrosheds_land_mask != 2)\n",
    "    return boolean_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dfbcc2-fd39-4900-815c-09a11c448b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger.\n",
    "logging_setup(verbose=verbose)\n",
    "_log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0742d7-6ca2-4286-9313-3efda5173f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support pathlib Paths.\n",
    "if aoi_vector_file is not None:\n",
    "    aoi_vector_file = str(aoi_vector_file)\n",
    "output_directory = str(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db4ad8-7193-47e4-a4b4-44085924a793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to use when loading datasets.\n",
    "dask_chunks = {\"x\": 3200, \"y\": 3200, \"time\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a0ca66-2695-42c8-968a-523151d514c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the area of interest as a GeoDataFrame.\n",
    "if aoi_vector_file is not None:\n",
    "    try:\n",
    "        aoi_gdf = gpd.read_file(aoi_vector_file)\n",
    "    except Exception as error:\n",
    "        _log.exception(f\"Could not read the file {aoi_vector_file}\")\n",
    "        raise error\n",
    "else:\n",
    "    aoi_gdf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b4349-4d9c-4e55-aae0-b661ccde8da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tile the wofs_ls_summary_alltime product.\n",
    "tiles, grid_workflow = tile_wofs_ls_summary_alltime(tile_size_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f134e90d-9c9a-47ca-86da-687846f2568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the tiles to the area of interest.\n",
    "filtered_tile_ids = filter_tiles(tiles, aoi_gdf, num_workers)\n",
    "filtered_tiles = {k: v for k, v in tiles.items() if k in filtered_tile_ids}\n",
    "_log.info(f\"Filtered out {len(tiles) - len(filtered_tiles)} tiles.\")\n",
    "_log.info(f\"Number of wofs_ls_summary_alltime tiles covering the area of interest: {len(filtered_tiles)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73816db0-7445-423a-a616-9966187a0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to write generated waterbody polygons to.\n",
    "polygons_from_thresholds_dir = os.path.join(output_directory, \"polygons_from_thresholds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a0c8b-9bc5-469e-8bc2-9a2a0588265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the filesystem to use.\n",
    "if check_if_s3_uri(polygons_from_thresholds_dir):\n",
    "    fs = fsspec.filesystem(\"s3\")\n",
    "else:\n",
    "    fs = fsspec.filesystem(\"file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe40837-f598-4d7c-a3fd-6c1deb2b0589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the directory exists. If it does not, create it.\n",
    "if not check_dir_exists(polygons_from_thresholds_dir):\n",
    "    fs.mkdirs(polygons_from_thresholds_dir, exist_ok=True)\n",
    "    _log.info(f\"Created directory {polygons_from_thresholds_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c85a8d3-9543-4a57-90b8-3ac5e6cae71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the wetness thresholds have been set correctly.\n",
    "min_wet_thresholds = set_wetness_thresholds(detection_threshold=detection_threshold, extent_threshold=extent_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f37f02-ce60-43c9-9dc4-4c5298b15a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the first set of polygons for each of the tiles.\n",
    "for tile in filtered_tiles.items():\n",
    "    tile_id = tile[0]\n",
    "    raster_polygons_fp = os.path.join(polygons_from_thresholds_dir, f\"{tile_id[0]}_{tile_id[1]}_raster_polygons.parquet\")\n",
    "\n",
    "    if not overwrite:\n",
    "        _log.info(f\"Checking existence of {raster_polygons_fp}\")\n",
    "        exists = check_file_exists(raster_polygons_fp)\n",
    "        if exists:\n",
    "            _log.info(f\"{raster_polygons_fp} exists! \\n Skipping generating water body polygons for {tile_id}.\")\n",
    "\n",
    "    if overwrite or not exists:\n",
    "        \n",
    "        try: \n",
    "            _log.info(f\"Generating water body polygons for tile {tile_id}\")\n",
    "            raster_polgyons = process_raster_polygons(tile=tile,\n",
    "                                                      grid_workflow=grid_workflow,\n",
    "                                                      dask_chunks=dask_chunks,\n",
    "                                                      min_valid_observations=min_valid_observations,\n",
    "                                                      min_wet_thresholds=min_wet_thresholds,\n",
    "                                                      land_sea_mask_fp=land_sea_mask_fp,\n",
    "                                                      filter_land_sea_mask=filter_hydrosheds_land_mask)\n",
    "            \n",
    "            # Write the polygons to parquet files.\n",
    "            raster_polgyons.to_parquet(raster_polygons_fp)\n",
    "            \n",
    "        except Exception as error:\n",
    "            _log.exception(\n",
    "                f\"\\nDataset {str(tile_id)} did not run. \\n\"\n",
    "            )\n",
    "            _log.exception(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d552b8-32fd-427c-835b-92245f627d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the extents for each tile.\n",
    "crs = grid_workflow.grid_spec.crs\n",
    "filtered_tiles_ids = [tile[0] for tile in filtered_tiles.items()]\n",
    "filtered_tiles_extents_geoms = [tile[1].geobox.extent.geom for tile in filtered_tiles.items()]\n",
    "filtered_tiles_extents_gdf = gpd.GeoDataFrame({\"tile_id\":filtered_tiles_ids, \"geometry\":filtered_tiles_extents_geoms}, crs=crs)\n",
    "\n",
    "filtered_tiles_extents_fp = os.path.join(\n",
    "    output_directory, \"tile_boundaries.parquet\"\n",
    ")\n",
    "\n",
    "filtered_tiles_extents_gdf.to_parquet(filtered_tiles_extents_fp)\n",
    "_log.info(f\"Tile boundaries written to {filtered_tiles_extents_fp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b394ffbb-bf75-4cc8-9c1c-09212772419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all parquet files for the first set of polygons.\n",
    "raster_polygon_paths = find_parquet_files(path=polygons_from_thresholds_dir, pattern=\".*raster_polygons.*\")\n",
    "_log.info(f\"Found {len(raster_polygon_paths)} parquet files for the raster polygons.\")\n",
    "\n",
    "# Load all polygons into a single GeoDataFrame.\n",
    "_log.info(\"Loading the raster polygons parquet files..\")\n",
    "raster_polygon_polygons_list = []\n",
    "for path in raster_polygon_paths:\n",
    "    gdf = gpd.read_parquet(path)\n",
    "    raster_polygon_polygons_list.append(gdf)\n",
    "\n",
    "raster_polygons = pd.concat(raster_polygon_polygons_list, ignore_index=True)\n",
    "_log.info(f\"Found {len(raster_polygons)} raster polygons.\")\n",
    "\n",
    "_log.info(\"Merging raster waterbody polygons located at tile boundaries...\")\n",
    "raster_polygons_merged = merge_polygons_at_tile_boundaries(\n",
    "    raster_polygons, filtered_tiles_extents_gdf\n",
    ")\n",
    "_log.info(f\"Raster polygons count {len(raster_polygons_merged)}.\")\n",
    "\n",
    "_log.info(\"Writing raster polygons merged at tile boundaries to disk..\")\n",
    "raster_polygons_output_fp = os.path.join(\n",
    "    output_directory, \"raster_polygons_merged_at_tile_boundaries.parquet\"\n",
    ")\n",
    "\n",
    "raster_polygons_merged.to_parquet(raster_polygons_output_fp)\n",
    "_log.info(f\"Polygons written to {raster_polygons_output_fp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
