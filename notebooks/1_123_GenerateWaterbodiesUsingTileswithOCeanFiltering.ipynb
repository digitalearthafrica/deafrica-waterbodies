{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6b0a31b-28d9-41d4-b59b-4ccb900e2528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import click\n",
    "import datacube\n",
    "import fsspec\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from deafrica_waterbodies.cli.logs import logging_setup\n",
    "from deafrica_waterbodies.io import (\n",
    "    check_dir_exists,\n",
    "    check_file_exists,\n",
    "    check_if_s3_uri,\n",
    "    find_parquet_files,\n",
    ")\n",
    "from deafrica_waterbodies.make_polygons import (\n",
    "    check_wetness_thresholds,\n",
    "    get_polygons_from_tile_with_land_sea_mask_filtering,\n",
    "    merge_polygons_at_tile_boundaries\n",
    ")\n",
    "from deafrica_waterbodies.tiling import (\n",
    "    filter_tiles,\n",
    "    get_tiles_ids,\n",
    "    tile_wofs_ls_summary_alltime,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c574ee-39c4-4931-b807-5d3f97900cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# These are the default AWS configurations for the Analysis Sandbox.\n",
    "# that are set in the environmnet variables.\n",
    "aws_default_config = {\n",
    "    # \"AWS_NO_SIGN_REQUEST\": \"YES\",\n",
    "    \"AWS_SECRET_ACCESS_KEY\": \"fake\",\n",
    "    \"AWS_ACCESS_KEY_ID\": \"fake\",\n",
    "}\n",
    "\n",
    "# To access public bucket, need to remove the AWS credentials in\n",
    "# the environment variables or the following error will occur.\n",
    "# PermissionError: The AWS Access Key Id you provided does not exist in our records.\n",
    "\n",
    "for key in aws_default_config.keys():\n",
    "    if key in os.environ:\n",
    "        del os.environ[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e50efa3-b5ba-44b3-b164-608d17e6413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 1\n",
    "\n",
    "aoi_vector_file = \"data/SenegalBasin.geojson\"\n",
    "tile_size_factor = 2\n",
    "num_workers = 16\n",
    "\n",
    "primary_threshold: float = 0.1\n",
    "secondary_threshold: float = 0.05\n",
    "minimum_valid_observations: int = 128\n",
    "output_directory = \"s3://deafrica-waterbodies-dev/test_out_dir/0-0-1/shapefile4\"\n",
    "overwrite = True\n",
    "land_sea_mask_fp = \"data/af_msk_3s.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e98a89fc-74fe-483b-89d5-b268c175d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "def filter_hydrosheds_land_mask(hydrosheds_land_mask: xr.DataArray) -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    Function to filter the HydroSHEDs Land Mask into a boolean mask.\n",
    "    \"\"\"\n",
    "    # Indicator values: 1 = land, 2 = ocean sink, 3 = inland sink, 255 is no data.\n",
    "    boolean_mask = (hydrosheds_land_mask != 255) & (hydrosheds_land_mask != 2)\n",
    "    return boolean_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2dfbcc2-fd39-4900-815c-09a11c448b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger.\n",
    "logging_setup(verbose=verbose)\n",
    "_log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d0742d7-6ca2-4286-9313-3efda5173f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support pathlib Paths.\n",
    "aoi_vector_file = str(aoi_vector_file)\n",
    "output_directory = str(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18db4ad8-7193-47e4-a4b4-44085924a793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to use when loading datasets.\n",
    "dask_chunks = {\"x\": 3200, \"y\": 3200, \"time\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95a0ca66-2695-42c8-968a-523151d514c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the area of interest as a GeoDataFrame.\n",
    "if aoi_vector_file is not None:\n",
    "    try:\n",
    "        aoi_gdf = gpd.read_file(aoi_vector_file)\n",
    "    except Exception as error:\n",
    "        _log.exception(f\"Could not read the file {aoi_vector_file}\")\n",
    "        raise error\n",
    "else:\n",
    "    aoi_gdf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea4b4349-4d9c-4e55-aae0-b661ccde8da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-06 21:08:36,060] {tiling.py:113} INFO - New tile size is (192000.0, 192000.0).\n",
      "[2023-10-06 21:08:38,617] {tiling.py:132} INFO - Number of wofs_ls_summary_alltime tiles: 1188\n"
     ]
    }
   ],
   "source": [
    "# Tile the wofs_ls_summary_alltime product.\n",
    "tiles, grid_workflow = tile_wofs_ls_summary_alltime(tile_size_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f134e90d-9c9a-47ca-86da-687846f2568c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1188it [00:03, 390.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# Filter the tiles to the area of interest.\n",
    "filtered_tile_ids = filter_tiles(tiles, aoi_gdf, num_workers)\n",
    "filtered_tiles = {k: v for k, v in tiles.items() if k in filtered_tile_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73816db0-7445-423a-a616-9966187a0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to write generated waterbody polygons to.\n",
    "polygons_from_thresholds_dir = os.path.join(output_directory, \"polygons_from_thresholds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "843a0c8b-9bc5-469e-8bc2-9a2a0588265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the filesystem to use.\n",
    "if check_if_s3_uri(polygons_from_thresholds_dir):\n",
    "    fs = fsspec.filesystem(\"s3\")\n",
    "else:\n",
    "    fs = fsspec.filesystem(\"file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbe40837-f598-4d7c-a3fd-6c1deb2b0589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-06 21:08:41,978] {credentials.py:620} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2023-10-06 21:08:42,201] {3896921575.py:4} INFO - Created directory s3://deafrica-waterbodies-dev/test_out_dir/0-0-1/shapefile4/polygons_from_thresholds\n"
     ]
    }
   ],
   "source": [
    "# Check if the directory exists. If it does not, create it.\n",
    "if not check_dir_exists(polygons_from_thresholds_dir):\n",
    "    fs.mkdirs(polygons_from_thresholds_dir, exist_ok=True)\n",
    "    _log.info(f\"Created directory {polygons_from_thresholds_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c85a8d3-9543-4a57-90b8-3ac5e6cae71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-06 21:08:42,205] {3616587049.py:3} INFO - We will be running a hybrid wetness threshold. \n",
      "**You have set 0.1 as the primary threshold, which will define the location of the waterbody polygons \n",
      " with 0.05 set as the supplementary threshold, which will define the extent/shape of the waterbody polygons.**\n"
     ]
    }
   ],
   "source": [
    "# Check if the wetness thresholds have been set correctly.\n",
    "minimum_wet_thresholds = [secondary_threshold, primary_threshold]\n",
    "_log.info(check_wetness_thresholds(minimum_wet_thresholds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26f37f02-ce60-43c9-9dc4-4c5298b15a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-06 21:08:42,212] {make_polygons.py:627} INFO - Generating water body polygons for tile (85, 49)\n",
      "[2023-10-06 21:08:51,413] {make_polygons.py:627} INFO - Generating water body polygons for tile (85, 50)\n",
      "[2023-10-06 21:08:57,968] {make_polygons.py:627} INFO - Generating water body polygons for tile (85, 46)\n",
      "[2023-10-06 21:09:06,354] {make_polygons.py:627} INFO - Generating water body polygons for tile (85, 48)\n",
      "[2023-10-06 21:09:15,018] {make_polygons.py:627} INFO - Generating water body polygons for tile (86, 47)\n",
      "[2023-10-06 21:09:24,055] {make_polygons.py:627} INFO - Generating water body polygons for tile (86, 50)\n",
      "[2023-10-06 21:09:30,576] {make_polygons.py:627} INFO - Generating water body polygons for tile (86, 48)\n",
      "[2023-10-06 21:09:38,003] {make_polygons.py:627} INFO - Generating water body polygons for tile (86, 49)\n",
      "[2023-10-06 21:09:45,036] {make_polygons.py:627} INFO - Generating water body polygons for tile (86, 46)\n",
      "[2023-10-06 21:09:56,578] {make_polygons.py:627} INFO - Generating water body polygons for tile (87, 47)\n",
      "[2023-10-06 21:10:38,041] {make_polygons.py:627} INFO - Generating water body polygons for tile (82, 49)\n",
      "[2023-10-06 21:11:08,888] {make_polygons.py:627} INFO - Generating water body polygons for tile (82, 48)\n",
      "[2023-10-06 21:11:17,872] {make_polygons.py:627} INFO - Generating water body polygons for tile (83, 48)\n",
      "[2023-10-06 21:11:28,670] {make_polygons.py:627} INFO - Generating water body polygons for tile (83, 49)\n",
      "[2023-10-06 21:11:52,870] {make_polygons.py:627} INFO - Generating water body polygons for tile (83, 47)\n",
      "[2023-10-06 21:12:03,693] {make_polygons.py:627} INFO - Generating water body polygons for tile (84, 47)\n",
      "[2023-10-06 21:12:11,475] {make_polygons.py:627} INFO - Generating water body polygons for tile (84, 48)\n",
      "[2023-10-06 21:12:23,154] {make_polygons.py:627} INFO - Generating water body polygons for tile (84, 46)\n",
      "[2023-10-06 21:12:33,559] {make_polygons.py:627} INFO - Generating water body polygons for tile (84, 45)\n",
      "[2023-10-06 21:12:42,260] {make_polygons.py:627} INFO - Generating water body polygons for tile (84, 50)\n",
      "[2023-10-06 21:12:49,233] {make_polygons.py:627} INFO - Generating water body polygons for tile (84, 49)\n",
      "[2023-10-06 21:12:57,253] {make_polygons.py:627} INFO - Generating water body polygons for tile (85, 47)\n",
      "[2023-10-06 21:13:06,321] {make_polygons.py:627} INFO - Generating water body polygons for tile (87, 48)\n"
     ]
    }
   ],
   "source": [
    "# Generate the first set of primary and secondary threhsold polygons for each of the tiles.\n",
    "for tile in filtered_tiles.items():\n",
    "    tile_id = tile[0]\n",
    "    primary_threshold_polygons_fp = os.path.join(\n",
    "        polygons_from_thresholds_dir, f\"{tile_id[0]}_{tile_id[1]}_primary_threshold_polygons.parquet\"\n",
    "    )\n",
    "    secondary_threshold_polygons_fp = os.path.join(\n",
    "        polygons_from_thresholds_dir, f\"{tile_id[0]}_{tile_id[1]}_secondary_threshold_polygons.parquet\"\n",
    "    )\n",
    "\n",
    "    if not overwrite:\n",
    "        _log.info(f\"Checking existence of {primary_threshold_polygons_fp} and {secondary_threshold_polygons_fp}\")\n",
    "        exists = check_file_exists(primary_threshold_polygons_fp) and check_file_exists(secondary_threshold_polygons_fp)\n",
    "\n",
    "    if overwrite or not exists:\n",
    "        (\n",
    "            primary_threshold_polygons,\n",
    "            secondary_threshold_polygons,\n",
    "        ) = get_polygons_from_tile_with_land_sea_mask_filtering(\n",
    "            tile=tile,\n",
    "            grid_workflow=grid_workflow,\n",
    "            dask_chunks=dask_chunks,\n",
    "            min_valid_observations=minimum_valid_observations,\n",
    "            primary_threshold=primary_threshold,\n",
    "            secondary_threshold=secondary_threshold,\n",
    "            land_sea_mask_fp=land_sea_mask_fp,\n",
    "            filter_land_sea_mask=filter_hydrosheds_land_mask,\n",
    "        )\n",
    "        # Write the polygons to parquet files.\n",
    "        primary_threshold_polygons.to_parquet(primary_threshold_polygons_fp)\n",
    "        secondary_threshold_polygons.to_parquet(secondary_threshold_polygons_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27d552b8-32fd-427c-835b-92245f627d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the extents for each tile.\n",
    "crs = grid_workflow.grid_spec.crs\n",
    "filtered_tiles_extents_geoms = [tile[1].geobox.extent.geom for tile in filtered_tiles.items()]\n",
    "filtered_tiles_extents_gdf = gpd.GeoDataFrame(geometry=filtered_tiles_extents_geoms, crs=crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ab0c48e-feeb-47c0-a13b-fbe3ee940ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-06 21:13:18,301] {2643269420.py:3} INFO - Found 23 parquet files for the primary threshold polygons.\n"
     ]
    }
   ],
   "source": [
    "# Find all parquet files for the primary threshold.\n",
    "primary_threshold_polygons_paths = find_parquet_files(path=polygons_from_thresholds_dir, pattern=\".*primary.*\")\n",
    "_log.info(f\"Found {len(primary_threshold_polygons_paths)} parquet files for the primary threshold polygons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfeb0c77-93d9-4cc6-a2d2-2542875abf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-06 21:13:18,305] {370454188.py:2} INFO - Loading the primary threshold polygons parquet files..\n",
      "[2023-10-06 21:13:20,706] {370454188.py:9} INFO - Found 58346 primary threshold polygons.\n"
     ]
    }
   ],
   "source": [
    "# Load all the primary threshold polygons into a single GeoDataFrame.\n",
    "_log.info(\"Loading the primary threshold polygons parquet files..\")\n",
    "primary_threshold_polygons_list = []\n",
    "for path in primary_threshold_polygons_paths:\n",
    "    gdf = gpd.read_parquet(path)\n",
    "    primary_threshold_polygons_list.append(gdf)\n",
    "\n",
    "primary_threshold_polygons = pd.concat(primary_threshold_polygons_list, ignore_index=True)\n",
    "_log.info(f\"Found {len(primary_threshold_polygons)} primary threshold polygons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e3fa531-851c-47f9-a9d4-87647b130da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-06 21:13:20,710] {1380469088.py:1} INFO - Merging primary threshold waterbody polygons located at tile boundaries...\n",
      "[2023-10-06 21:13:25,592] {1380469088.py:5} INFO - Primary threshold polygons count 58265.\n"
     ]
    }
   ],
   "source": [
    "_log.info(\"Merging primary threshold waterbody polygons located at tile boundaries...\")\n",
    "primary_threshold_polygons_merged = merge_polygons_at_tile_boundaries(\n",
    "    primary_threshold_polygons, filtered_tiles_extents_gdf\n",
    ")\n",
    "_log.info(f\"Primary threshold polygons count {len(primary_threshold_polygons_merged)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70430dbd-8ef5-46cb-8def-c9cf5c0dda35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-06 21:13:25,597] {3770163632.py:1} INFO - Writing primary threshold polygons merged at tile boundaries to disk..\n",
      "[2023-10-06 21:13:26,024] {3770163632.py:7} INFO - Polygons written to s3://deafrica-waterbodies-dev/test_out_dir/0-0-1/shapefile4/primary_threshold_polygons_merged_at_tile_boundaries.parquet\n"
     ]
    }
   ],
   "source": [
    "_log.info(\"Writing primary threshold polygons merged at tile boundaries to disk..\")\n",
    "primary_threshold_polygons_output_fp = os.path.join(\n",
    "    output_directory, \"primary_threshold_polygons_merged_at_tile_boundaries.parquet\"\n",
    ")\n",
    "\n",
    "primary_threshold_polygons_merged.to_parquet(primary_threshold_polygons_output_fp)\n",
    "_log.info(f\"Polygons written to {primary_threshold_polygons_output_fp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70440491-216a-42d6-b26e-c943b918a6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-06 21:13:26,060] {1989755468.py:3} INFO - Found 23 parquet files for the secondary threshold polygons.\n"
     ]
    }
   ],
   "source": [
    "# Find all parquet files for the secondary threshold.\n",
    "secondary_threshold_polygons_paths = find_parquet_files(path=polygons_from_thresholds_dir, pattern=\".*secondary.*\")\n",
    "_log.info(f\"Found {len(secondary_threshold_polygons_paths)} parquet files for the secondary threshold polygons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "096b45e5-caf9-4df4-8d36-b96cfb733d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-06 21:13:26,065] {4278796675.py:2} INFO - Loading the secondary threshold polygons parquet files...\n",
      "[2023-10-06 21:13:28,841] {4278796675.py:9} INFO - Found 113781 secondary threshold polygons.\n"
     ]
    }
   ],
   "source": [
    "# Load all the secondary threshold polygons into a single GeoDataFrame.\n",
    "_log.info(\"Loading the secondary threshold polygons parquet files...\")\n",
    "secondary_threshold_polygons_list = []\n",
    "for path in secondary_threshold_polygons_paths:\n",
    "    gdf = gpd.read_parquet(path)\n",
    "    secondary_threshold_polygons_list.append(gdf)\n",
    "\n",
    "secondary_threshold_polygons = pd.concat(secondary_threshold_polygons_list, ignore_index=True)\n",
    "_log.info(f\"Found {len(secondary_threshold_polygons)} secondary threshold polygons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b010dca0-9357-4a94-936c-b36e3500e7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-06 21:13:28,845] {2540286757.py:1} INFO - Merging secondary threshold waterbody polygons located at dataset/scene boundaries...\n",
      "[2023-10-06 21:13:41,709] {2540286757.py:5} INFO - Secondary threshold polygons count 113649.\n"
     ]
    }
   ],
   "source": [
    "_log.info(\"Merging secondary threshold waterbody polygons located at dataset/scene boundaries...\")\n",
    "secondary_threshold_polygons_merged = merge_polygons_at_tile_boundaries(\n",
    "    secondary_threshold_polygons, filtered_tiles_extents_gdf\n",
    ")\n",
    "_log.info(f\"Secondary threshold polygons count {len(secondary_threshold_polygons_merged)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "703dc6e4-8ce0-48a3-851b-22355daed66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-06 21:13:41,714] {1287271369.py:1} INFO - Writing secondary threshold polygons merged at tile boundaries to disk..\n",
      "[2023-10-06 21:13:42,312] {1287271369.py:8} INFO - Polygons written to s3://deafrica-waterbodies-dev/test_out_dir/0-0-1/shapefile4/secondary_threshold_polygons_merged_at_ds_boundaries.parquet\n"
     ]
    }
   ],
   "source": [
    "_log.info(\"Writing secondary threshold polygons merged at tile boundaries to disk..\")\n",
    "secondary_threshold_polygons_output_fp = os.path.join(\n",
    "    output_directory, \"secondary_threshold_polygons_merged_at_ds_boundaries.parquet\"\n",
    ")\n",
    "\n",
    "secondary_threshold_polygons_merged.to_parquet(secondary_threshold_polygons_output_fp)\n",
    "\n",
    "_log.info(f\"Polygons written to {secondary_threshold_polygons_output_fp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
