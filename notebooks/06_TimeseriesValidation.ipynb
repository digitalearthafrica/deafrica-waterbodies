{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0264e62-ef13-44c9-8b62-603f49dddcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/geopandas/_compat.py:124: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_240/348742901.py:2: DeprecationWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas still uses PyGEOS by default. However, starting with version 0.14, the default will switch to Shapely. To force to use Shapely 2.0 now, you can either uninstall PyGEOS or set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In the next release, GeoPandas will switch to using Shapely by default, even if PyGEOS is installed. If you only have PyGEOS installed to get speed-ups, this switch should be smooth. However, if you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "import datacube\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from deafrica_tools.classification import HiddenPrints\n",
    "from deafrica_tools.datahandling import wofs_fuser\n",
    "from deafrica_tools.spatial import xr_rasterize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4934249e-647a-4b49-8e13-ce906c1d9d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "waterbodies_vector_file = 'data/senegalbasinwaterbodies.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68a2f65b-ca36-4c17-be0f-6f8f71a7d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_timeseries(waterbodies_vector_file, waterbody_uid):\n",
    "    # read the polgon shapefile\n",
    "    polygons_gdf = gpd.read_file(waterbodies_vector_file)\n",
    "    \n",
    "    # select a given waterbody using the UID \n",
    "    waterbody_gdf = polygons_gdf.loc[polygons_gdf['UID'].isin([waterbody_uid])]\n",
    "    \n",
    "    # extract the timeseries link from the geodataframe\n",
    "    timeseries_link = waterbody_gdf['timeseries']\n",
    "    timeseries_link = timeseries_link.item()\n",
    "    \n",
    "    # read the timeseries csv\n",
    "    waterbody_csv = pd.read_csv(timeseries_link)\n",
    "    \n",
    "    return waterbody_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4adf1515-6027-4a4f-91db-7eda47fb51e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_value_comparison(last_obs, waterbodies_vector_file, waterbody_uid):\n",
    "    # read the polgon shapefile\n",
    "    polygons_gdf = gpd.read_file(waterbodies_vector_file)\n",
    "    \n",
    "    # select a given waterbody using the UID \n",
    "    waterbody_gdf = polygons_gdf.loc[polygons_gdf['UID'].isin([waterbody_uid])]\n",
    "    \n",
    "    last_obs = last_obs.iloc[-1]\n",
    "    time = last_obs['date'][:10]\n",
    "    print(time)\n",
    "    \n",
    "    with HiddenPrints():\n",
    "        dc = datacube.Datacube(app=\"timeseries_test\")\n",
    "        aoi = waterbody_gdf\n",
    "        # get the latitude and longitude range of the waterbody\n",
    "        lat_range = (aoi.total_bounds[1], aoi.total_bounds[3])\n",
    "        lon_range = (aoi.total_bounds[0], aoi.total_bounds[2])\n",
    "        \n",
    "        output_crs = 'EPSG:6933'\n",
    "        query = {'x': lon_range,\n",
    "                'y': lat_range,\n",
    "                'time': time}\n",
    "        wofls= dc.load(product = 'wofs_ls',\n",
    "               group_by=\"solar_day\",\n",
    "               fuse_func=wofs_fuser,\n",
    "               output_crs = output_crs,\n",
    "               collection_category=\"T1\",\n",
    "               resolution=(-30,30),\n",
    "               **query)\n",
    "    wofls_ds = wofls.water\n",
    "    # Generate a polygon mask to keep only data within the waterbody polygon\n",
    "    polygon_mask = xr_rasterize(waterbody_gdf, wofls_ds)\n",
    "    # Mask dataset to set pixels outside of the polygon to 'NaN'\n",
    "    wofls_masked = wofls_ds.where(polygon_mask)\n",
    "    waterbody_mask = wofls_masked.notnull()\n",
    "    \n",
    "    # masked waterbody pixel count \n",
    "    pixel_count = (wofls_masked.notnull()).sum().item()\n",
    "    \n",
    "    # Number of pixels observed to be valid (clear) and wet\n",
    "    valid_and_wet = (wofls_masked == 128)\n",
    "    valid_and_wet_count = valid_and_wet.where(waterbody_mask).sum().item()\n",
    "    valid_and_wet_count\n",
    "    # Number of pixels observed to be valid (clear) and dry\n",
    "    valid_and_dry = (wofls_masked == 0)\n",
    "    valid_and_dry_count = valid_and_dry.where(waterbody_mask).sum().item()\n",
    "    valid_and_dry_count\n",
    "    # Number of pixels observed to be invalid \n",
    "    invalid = ~wofls_masked.isin([128, 0])\n",
    "    invalid_count = invalid.where(waterbody_mask).sum().item()\n",
    "    \n",
    "    # Percentages\n",
    "    valid_and_wet_percentage = (valid_and_wet_count / pixel_count) * 100\n",
    "    valid_and_dry_percentage = (valid_and_dry_count / pixel_count) * 100\n",
    "    invalid_percentage = (invalid_count / pixel_count) * 100\n",
    "    \n",
    "    data = {'Attributes':['pc_wet','px_wet', 'pc_dry', 'px_dry', 'pc_invalid', 'px_invalid'],\n",
    "       'CSV Results':[last_obs['pc_wet'],\n",
    "              last_obs['px_wet'], \n",
    "              last_obs['pc_dry'], \n",
    "              last_obs['px_dry'], \n",
    "              last_obs['pc_invalid'], \n",
    "              last_obs['px_invalid']],\n",
    "       'Validation Results':[valid_and_wet_percentage, \n",
    "                             valid_and_wet_count, \n",
    "                             valid_and_dry_percentage, \n",
    "                             valid_and_dry_count, \n",
    "                             invalid_percentage, \n",
    "                             invalid_count],\n",
    "       'Difference': [last_obs['pc_wet']-valid_and_wet_percentage,\n",
    "                     last_obs['px_wet']-valid_and_wet_count,\n",
    "                     last_obs['pc_dry']-valid_and_dry_percentage,\n",
    "                     last_obs['px_dry']-valid_and_dry_count,\n",
    "                     last_obs['pc_invalid']-invalid_percentage,\n",
    "                     last_obs['px_invalid']-invalid_count,]}\n",
    "    comparison_df = pd.DataFrame(data) \n",
    "    return comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7f54bdb-66ae-4b4c-9a7f-ca81735163a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edumqvmx9\n",
      "2019-03-24\n",
      "CSV Wet and Dry Observation Value Comparison\n",
      "   Attributes   CSV Results  Validation Results  Difference\n",
      "0      pc_wet     28.930588           28.956167    -0.02558\n",
      "1      px_wet  15834.000000        15848.000000   -14.00000\n",
      "2      pc_dry     71.069412           71.043833     0.02558\n",
      "3      px_dry  38897.000000        38883.000000    14.00000\n",
      "4  pc_invalid      0.000000            0.000000     0.00000\n",
      "5  px_invalid      0.000000            0.000000     0.00000\n",
      "2019-02-28\n",
      "CSV Wet, Dry and Invalid Observation Value Comparison\n",
      "   Attributes   CSV Results  Validation Results    Difference\n",
      "0      pc_wet     12.755111           12.742322  1.278983e-02\n",
      "1      px_wet   6981.000000         6974.000000  7.000000e+00\n",
      "2      pc_dry     87.215655           87.228445 -1.278983e-02\n",
      "3      px_dry  47734.000000        47741.000000 -7.000000e+00\n",
      "4  pc_invalid      0.029234            0.029234 -3.469447e-17\n",
      "5  px_invalid     16.000000           16.000000  0.000000e+00\n",
      "2019-02-12\n",
      "CSV Invalid Observation Value Comparison\n",
      "   Attributes  CSV Results  Validation Results  Difference\n",
      "0      pc_wet          NaN                 0.0         NaN\n",
      "1      px_wet          NaN                 0.0         NaN\n",
      "2      pc_dry          NaN                 0.0         NaN\n",
      "3      px_dry          NaN                 0.0         NaN\n",
      "4  pc_invalid        100.0               100.0         0.0\n",
      "5  px_invalid      54731.0             54731.0         0.0\n"
     ]
    }
   ],
   "source": [
    "waterbody_uid = ['edumqvmx9']#efc3cy8ek','een136fc6','ef3ubzgvj']'edumqvmx9', 'eduk7jbjz'\n",
    "\n",
    "for uid in waterbody_uid:\n",
    "    waterbody_timeseries = extract_timeseries(waterbodies_vector_file, uid)\n",
    "    \n",
    "    # returns observations that have been observed as wet and dry  \n",
    "    csv_wet_dry = waterbody_timeseries[waterbody_timeseries['pc_wet']>10]\n",
    "    csv_wet_dry = csv_wet_dry.drop(csv_wet_dry[csv_wet_dry['pc_invalid']>0].index)\n",
    "    \n",
    "    # returns observations that have been observed as invalid less than 10%  \n",
    "    csv_wet_dry_invalid = waterbody_timeseries[waterbody_timeseries['pc_wet']>10]\n",
    "    # remove observations that are not invalid \n",
    "    csv_wet_dry_invalid = csv_wet_dry_invalid.drop(csv_wet_dry_invalid[csv_wet_dry_invalid['pc_invalid']==0].index)\n",
    "    # returns last invalid observation over 50%  \n",
    "    invalid_obs = waterbody_timeseries[waterbody_timeseries['pc_invalid']>50]\n",
    "    \n",
    "    print(uid)\n",
    "    \n",
    "    try:   \n",
    "        csv_wet_dry_comparison = timeseries_value_comparison(csv_wet_dry, waterbodies_vector_file, uid)\n",
    "        print('CSV Wet and Dry Observation Value Comparison')\n",
    "        print(csv_wet_dry_comparison)\n",
    "    except:\n",
    "        print('Could not complete wet and dry observation value comparison.')\n",
    "    \n",
    "    try:\n",
    "        csv_wet_dry_invalid_comparison = timeseries_value_comparison(csv_wet_dry_invalid, waterbodies_vector_file, uid)\n",
    "        print('CSV Wet, Dry and Invalid Observation Value Comparison')\n",
    "        print(csv_wet_dry_invalid_comparison)\n",
    "    except:\n",
    "        print('Could not complete wet, dry and invalid observation value comparison.')\n",
    "    \n",
    "    try:\n",
    "        csv_invalid_comparison = timeseries_value_comparison(invalid_obs, waterbodies_vector_file, uid)\n",
    "        print('CSV Invalid Observation Value Comparison')\n",
    "        print(csv_invalid_comparison)\n",
    "    except:\n",
    "        print('Could not complete invalid observation value comparison.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b468464a-26d3-4f60-a06f-8faf4938f4de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
